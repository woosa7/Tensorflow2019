{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제12장 이미지생성\n",
    "\n",
    "### BEGAN (Boundary Equilibrium GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discriminator로 CAE (Convolutional auto-encoder) 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****공통 모듈 읽어들이기****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1388,
     "status": "ok",
     "timestamp": 1516713481299,
     "user": {
      "displayName": "Mitsuhisa Ohta",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "107586005588721640993"
     },
     "user_tz": -540
    },
    "id": "6EoENk-rlqG-",
    "outputId": "0492c79c-6897-453d-8015-b00afd1583da"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Conv2D, Conv2DTranspose, Activation, Flatten, Dense, UpSampling2D, Reshape, Lambda, Input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이미지를 저장하는 함수**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(path, imgs, rows, cols):\n",
    "    \"\"\"이미지를 타일 형태로 저장\n",
    "    \n",
    "    Arguments:\n",
    "        path (str): 저장할 폴더 경로\n",
    "        imgs (np.array): 저장할 이미지 리스트\n",
    "        rows (int): 타일의 세로 크기\n",
    "        cols (int): 타일의 가로 크기\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    base_width = imgs.shape[1]\n",
    "    base_height = imgs.shape[2]\n",
    "    channels = imgs.shape[3]\n",
    "    output_shape = (\n",
    "        base_height*rows,\n",
    "        base_width*cols,\n",
    "        channels\n",
    "    )\n",
    "    buffer = np.zeros(output_shape)\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            img = imgs[row*cols + col]\n",
    "            buffer[\n",
    "                row*base_height:(row + 1)*base_height,\n",
    "                col*base_width:(col + 1)*base_width\n",
    "            ] = img\n",
    "    array_to_img(buffer).save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PZhh5kkDFbXK"
   },
   "source": [
    "**예제 코드12.1:이미지 데이터 읽어 들이기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1516713490057,
     "user": {
      "displayName": "Mitsuhisa Ohta",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "107586005588721640993"
     },
     "user_tz": -540
    },
    "id": "_8jJdMsfmFQx",
    "outputId": "396afe0c-b66c-4559-ed55-c24ad3b316f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19370 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'data/chap12/'\n",
    "BATCH_SIZE = 16\n",
    "IMG_SHAPE = (64, 64, 3)\n",
    "\n",
    "data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "train_data_generator = data_gen.flow_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    classes=['faces'],\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=IMG_SHAPE[:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHbFoscwFiPI"
   },
   "source": [
    "**예제 코드12.2:Encoder 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LLFOMimZmKR_"
   },
   "outputs": [],
   "source": [
    "def build_encoder(input_shape, z_size, n_filters, n_layers):\n",
    "    \"\"\"Encoder구축\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape (int): 이미지의 shape\n",
    "        z_size (int): 특징 공간의 차원 수\n",
    "        n_filters (int): 파일 수\n",
    "        \n",
    "    Returns:\n",
    "        model (Model): 인코더 모델 \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(n_filters, 3, activation='elu', input_shape=input_shape, padding='same'))\n",
    "    model.add(Conv2D(n_filters, 3, padding='same'))\n",
    "    \n",
    "    for i in range(2, n_layers + 1):\n",
    "        model.add(Conv2D(i*n_filters, 3, activation='elu', padding='same'))\n",
    "        model.add(Conv2D(i*n_filters, 3, activation='elu', strides=2, padding='same'))\n",
    "        \n",
    "    model.add(Conv2D(n_layers*n_filters, 3, padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(z_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제 코드12.3:생성자/Decoder 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "elVBPfr-mONR"
   },
   "outputs": [],
   "source": [
    "def build_decoder(output_shape, z_size, n_filters, n_layers):\n",
    "    \"\"\"Decoder 구축\n",
    "    \n",
    "    Arguments:\n",
    "        output_shape (np.array): 이미지 shape\n",
    "        z_size (int): 특징 공간의 차원 수\n",
    "        n_filters (int): 파일 수\n",
    "        n_layers (int): 레이어 수\n",
    "        \n",
    "    Returns:\n",
    "        model (Model): 디코더 모델 \n",
    "    \"\"\"\n",
    "    # UpSampling2D로 몇 배로 확대할지 계산\n",
    "    scale = 2**(n_layers - 1)\n",
    "    # 합성곱층의 처음 입력 사이즈를 scale로부터 역산\n",
    "    fc_shape = (\n",
    "        output_shape[0]//scale,\n",
    "        output_shape[1]//scale,\n",
    "        n_filters\n",
    "    )\n",
    "    # 완전연결 계층에서 필요한 사이즈를 역산\n",
    "    fc_size = fc_shape[0]*fc_shape[1]*fc_shape[2]\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # 완전연결 계층\n",
    "    model.add(Dense(fc_size, input_shape=(z_size,)))\n",
    "    model.add(Reshape(fc_shape))\n",
    "    \n",
    "    # 합성곱층 반복\n",
    "    for i in range(n_layers - 1):\n",
    "        model.add(Conv2D(n_filters, 3, activation='elu', padding='same'))\n",
    "        model.add(Conv2D(n_filters, 3, activation='elu', padding='same'))\n",
    "        model.add(UpSampling2D())\n",
    "        \n",
    "    # 마지막 층은 UpSampling2D가 불필요\n",
    "    model.add(Conv2D(n_filters, 3, activation='elu', padding='same'))\n",
    "    model.add(Conv2D(n_filters, 3, activation='elu', padding='same'))\n",
    "\n",
    "    # 출력층에서는 3채널로\n",
    "    model.add(Conv2D(3, 3, padding='same'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제 코드12.4:생성자 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XoubtmhlmQh3"
   },
   "outputs": [],
   "source": [
    "def build_generator(img_shape, z_size, n_filters, n_layers):\n",
    "    decoder = build_decoder(\n",
    "        img_shape, z_size, n_filters, n_layers\n",
    "    )\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제 코드12.5:구분자 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IHMwgdgYmSwO"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape, z_size, n_filters, n_layers):\n",
    "    # CAE\n",
    "    encoder = build_encoder(\n",
    "        img_shape, z_size, n_filters, n_layers\n",
    "    )\n",
    "    decoder = build_decoder(\n",
    "        img_shape, z_size, n_filters, n_layers\n",
    "    )\n",
    "    return keras.models.Sequential((encoder, decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제 코드12.6:구분자의 학습용 네트워크**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RbEZL3qtmU5a"
   },
   "outputs": [],
   "source": [
    "def build_discriminator_trainer(discriminator):\n",
    "    img_shape = discriminator.input_shape[1:]\n",
    "    real_inputs = Input(img_shape)\n",
    "    fake_inputs = Input(img_shape)\n",
    "    real_outputs = discriminator(real_inputs)\n",
    "    fake_outputs = discriminator(fake_inputs)\n",
    "\n",
    "    return Model(\n",
    "        inputs=[real_inputs, fake_inputs],\n",
    "        outputs=[real_outputs, fake_outputs]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제 코드12.7:네트워크 구축**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 731,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1516713509294,
     "user": {
      "displayName": "Mitsuhisa Ohta",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "107586005588721640993"
     },
     "user_tz": -540
    },
    "id": "KYSTnemdmXJL",
    "outputId": "50373191-3bb8-4ee3-b587-6dd979b042b2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mingks\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\mingks\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:439: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4096)              135168    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 3)         1731      \n",
      "=================================================================\n",
      "Total params: 432,323\n",
      "Trainable params: 432,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 4096)              135168    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 64, 3)         1731      \n",
      "=================================================================\n",
      "Total params: 432,323\n",
      "Trainable params: 432,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_filters = 64  #  필터 수\n",
    "n_layers = 4 # 레이어 수\n",
    "z_size = 32  #  특징 공간의 차원\n",
    "\n",
    "generator = build_generator(\n",
    "    IMG_SHAPE, z_size, n_filters, n_layers\n",
    ")\n",
    "discriminator = build_discriminator(\n",
    "    IMG_SHAPE, z_size, n_filters, n_layers\n",
    ")\n",
    "discriminator_trainer = build_discriminator_trainer(\n",
    "    discriminator\n",
    ")\n",
    "\n",
    "generator.summary()\n",
    "# discriminator.layers[1]은 디코더를 나타냄\n",
    "discriminator.layers[1].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제 코드12.8:손실 함수 정의**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-i1VQ67WmeFz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.losses import mean_absolute_error\n",
    "\n",
    "\n",
    "def build_generator_loss(discriminator):\n",
    "    # discriminator를 사용해서 손실 함수 정의\n",
    "    def loss(y_true, y_pred):\n",
    "        # y_true はダミー\n",
    "        reconst = discriminator(y_pred)\n",
    "        return mean_absolute_error(\n",
    "            reconst,\n",
    "            y_pred\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제 코드12.9:generator 컴파일**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8xlrAPpOmhAf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 초기 학습률(Generator)\n",
    "g_lr = 0.0001\n",
    "\n",
    "generator_loss = build_generator_loss(discriminator)\n",
    "generator.compile(\n",
    "    loss=generator_loss,\n",
    "    optimizer=Adam(g_lr)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제 코드12.10:구분자 컴파일**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FcOeTJ1qmjub"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mingks\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:125: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# 초기 학습률(Discriminator)\n",
    "d_lr = 0.0001\n",
    "\n",
    "# k_var는 수치(일반 변수)\n",
    "k_var = 0.0\n",
    "# k はKeras(TensorFlow) のVariable\n",
    "k = K.variable(k_var)\n",
    "discriminator_trainer.compile(\n",
    "    loss=[\n",
    "        mean_absolute_error,\n",
    "        mean_absolute_error\n",
    "    ],\n",
    "    loss_weights=[1., -k],\n",
    "    optimizer=Adam(d_lr)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제 코드12.11:수렴 판정용 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(real_loss, fake_loss, gamma):\n",
    "    return real_loss + np.abs(gamma*real_loss - fake_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_e7mjM3F4Cg"
   },
   "source": [
    "**예제 코드12.12*학습 코드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 434,
     "output_extras": [
      {
       "item_id": 2
      },
      {
       "item_id": 3
      },
      {
       "item_id": 4
      }
     ]
    },
    "colab_type": "code",
    "id": "ksY4_jqFml8y",
    "outputId": "669c8c2b-c62e-4b42-f52f-e0aa03548987",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mingks\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3067: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "{'k': -0.00047289272, 'measure': 1.418678104877472, 'real_loss': 0.9457854, 'fake_loss': 0.9457854}\n",
      "{'k': -0.07920497, 'measure': 0.2361962212845683, 'real_loss': 0.05136793, 'fake_loss': 0.05136793}\n",
      "{'k': -0.118591346, 'measure': 0.11823619798198343, 'real_loss': 0.06784205, 'fake_loss': 0.06784205}\n",
      "{'k': -0.15363362, 'measure': 0.10522857859544456, 'real_loss': 0.033345547, 'fake_loss': 0.033345547}\n",
      "{'k': -0.17890067, 'measure': 0.0758511664448306, 'real_loss': 0.025826242, 'fake_loss': 0.025826242}\n",
      "{'k': -0.19959486, 'measure': 0.06212127793114632, 'real_loss': 0.043241024, 'fake_loss': 0.043241024}\n",
      "{'k': -0.22036536, 'measure': 0.062311517434660346, 'real_loss': 0.047195844, 'fake_loss': 0.047195844}\n",
      "{'k': -0.23881513, 'measure': 0.055420100613031535, 'real_loss': 0.020237759, 'fake_loss': 0.020237759}\n",
      "{'k': -0.25456056, 'measure': 0.047266687262803316, 'real_loss': 0.02103718, 'fake_loss': 0.02103718}\n",
      "{'k': -0.26871055, 'measure': 0.04248155668610707, 'real_loss': 0.04457189, 'fake_loss': 0.04457189}\n",
      "{'k': -0.2818271, 'measure': 0.03941646126005799, 'real_loss': 0.023382159, 'fake_loss': 0.023382159}\n",
      "{'k': -0.29387078, 'measure': 0.036166082058101894, 'real_loss': 0.010094127, 'fake_loss': 0.010094127}\n",
      "{'k': -0.3046818, 'measure': 0.03243312324676663, 'real_loss': 0.029584091, 'fake_loss': 0.029584091}\n",
      "{'k': -0.31455868, 'measure': 0.02967501260479912, 'real_loss': 0.01837404, 'fake_loss': 0.01837404}\n",
      "{'k': -0.32429162, 'measure': 0.029226359067019075, 'real_loss': 0.010264695, 'fake_loss': 0.010264695}\n",
      "{'k': -0.33262035, 'measure': 0.02500159091851674, 'real_loss': 0.02172871, 'fake_loss': 0.02172871}\n",
      "{'k': -0.34046784, 'measure': 0.023575005403719842, 'real_loss': 0.02380063, 'fake_loss': 0.02380063}\n",
      "{'k': -0.34800825, 'measure': 0.022656986331799998, 'real_loss': 0.009953182, 'fake_loss': 0.009953182}\n",
      "{'k': -0.35538685, 'measure': 0.02213576441584155, 'real_loss': 0.012505931, 'fake_loss': 0.012505931}\n",
      "{'k': -0.3619194, 'measure': 0.019616463823942467, 'real_loss': 0.006736896, 'fake_loss': 0.006736896}\n",
      "{'k': -0.3682255, 'measure': 0.01892837751377374, 'real_loss': 0.017423874, 'fake_loss': 0.017423874}\n",
      "{'k': -0.37416366, 'measure': 0.01784061905625276, 'real_loss': 0.008748217, 'fake_loss': 0.008748217}\n",
      "{'k': -0.37940875, 'measure': 0.015748409250983968, 'real_loss': 0.009123184, 'fake_loss': 0.009123184}\n",
      "{'k': -0.38521662, 'measure': 0.017423589529003948, 'real_loss': 0.00991929, 'fake_loss': 0.00991929}\n",
      "{'k': -0.390059, 'measure': 0.014542039694264531, 'real_loss': 0.01437231, 'fake_loss': 0.01437231}\n",
      "{'k': -0.39476734, 'measure': 0.014146538545377552, 'real_loss': 0.008214238, 'fake_loss': 0.008214238}\n",
      "{'k': -0.39934513, 'measure': 0.013745695230667479, 'real_loss': 0.011663923, 'fake_loss': 0.011663923}\n",
      "{'k': -0.40366128, 'measure': 0.01296591859369073, 'real_loss': 0.008970013, 'fake_loss': 0.008970013}\n",
      "{'k': -0.40794915, 'measure': 0.012877114623086527, 'real_loss': 0.006705313, 'fake_loss': 0.006705313}\n",
      "{'k': -0.4119468, 'measure': 0.0119929798648227, 'real_loss': 0.013573044, 'fake_loss': 0.013573044}\n",
      "{'k': -0.41593522, 'measure': 0.011985566746909171, 'real_loss': 0.009648105, 'fake_loss': 0.009648105}\n",
      "{'k': -0.41980654, 'measure': 0.011628445970476605, 'real_loss': 0.0083586285, 'fake_loss': 0.0083586285}\n",
      "{'k': -0.42333928, 'measure': 0.01061078436335083, 'real_loss': 0.004740634, 'fake_loss': 0.004740634}\n",
      "{'k': -0.42680094, 'measure': 0.010392047845060006, 'real_loss': 0.008272277, 'fake_loss': 0.008272277}\n",
      "{'k': -0.43024144, 'measure': 0.010333927799365483, 'real_loss': 0.0078105573, 'fake_loss': 0.0078105573}\n",
      "{'k': -0.43360773, 'measure': 0.010098824045271612, 'real_loss': 0.0041979705, 'fake_loss': 0.0041979705}\n",
      "{'k': -0.43697757, 'measure': 0.010115849148016423, 'real_loss': 0.004910291, 'fake_loss': 0.004910291}\n",
      "{'k': -0.43990806, 'measure': 0.008798803104786203, 'real_loss': 0.0027282028, 'fake_loss': 0.0027282028}\n",
      "{'k': -0.44300103, 'measure': 0.009283058608300053, 'real_loss': 0.0029784937, 'fake_loss': 0.0029784937}\n",
      "{'k': -0.44586495, 'measure': 0.008596224255859852, 'real_loss': 0.0068461746, 'fake_loss': 0.0068461746}\n",
      "{'k': -0.44887584, 'measure': 0.00904292914189864, 'real_loss': 0.003202323, 'fake_loss': 0.003202323}\n",
      "{'k': -0.4514891, 'measure': 0.00783973377244547, 'real_loss': 0.0051351516, 'fake_loss': 0.0051351516}\n",
      "{'k': -0.45426843, 'measure': 0.008345758124662098, 'real_loss': 0.0025600852, 'fake_loss': 0.0025600852}\n",
      "{'k': -0.4568024, 'measure': 0.007605690646392759, 'real_loss': 0.0043495493, 'fake_loss': 0.0043495493}\n",
      "{'k': -0.45950755, 'measure': 0.008121991403808352, 'real_loss': 0.0044799335, 'fake_loss': 0.0044799335}\n",
      "{'k': -0.46201786, 'measure': 0.007537704753514845, 'real_loss': 0.0067310277, 'fake_loss': 0.0067310277}\n",
      "{'k': -0.46449563, 'measure': 0.007433298816613388, 'real_loss': 0.0040505356, 'fake_loss': 0.0040505356}\n",
      "{'k': -0.46705922, 'measure': 0.00769681641011266, 'real_loss': 0.0050718696, 'fake_loss': 0.0050718696}\n",
      "{'k': -0.46921682, 'measure': 0.0064804154241574, 'real_loss': 0.0041866717, 'fake_loss': 0.0041866717}\n",
      "{'k': -0.47164536, 'measure': 0.0072918770952383055, 'real_loss': 0.0051735286, 'fake_loss': 0.0051735286}\n",
      "{'k': -0.47400424, 'measure': 0.0070844298441661525, 'real_loss': 0.0032400235, 'fake_loss': 0.0032400235}\n",
      "{'k': -0.47611442, 'measure': 0.006335421313822735, 'real_loss': 0.0038837658, 'fake_loss': 0.0038837658}\n",
      "{'k': -0.47828284, 'measure': 0.006505230207229033, 'real_loss': 0.002806988, 'fake_loss': 0.002806988}\n",
      "{'k': -0.48037234, 'measure': 0.006272701632755343, 'real_loss': 0.004968318, 'fake_loss': 0.004968318}\n",
      "{'k': -0.4824693, 'measure': 0.0062982795608695595, 'real_loss': 0.0016637444, 'fake_loss': 0.0016637444}\n",
      "{'k': -0.48437476, 'measure': 0.005718905311601702, 'real_loss': 0.009156875, 'fake_loss': 0.009156875}\n",
      "{'k': -0.4863636, 'measure': 0.005980246310471557, 'real_loss': 0.0035097692, 'fake_loss': 0.0035097692}\n",
      "{'k': -0.48817897, 'measure': 0.0054514122680411675, 'real_loss': 0.0030272924, 'fake_loss': 0.0030272924}\n",
      "{'k': -0.49010652, 'measure': 0.005782639148994349, 'real_loss': 0.0040308526, 'fake_loss': 0.0040308526}\n",
      "{'k': -0.4919566, 'measure': 0.00555623558111256, 'real_loss': 0.005238913, 'fake_loss': 0.005238913}\n",
      "{'k': -0.49392262, 'measure': 0.005906012926425319, 'real_loss': 0.006165158, 'fake_loss': 0.006165158}\n",
      "{'k': -0.49566925, 'measure': 0.005249108144023921, 'real_loss': 0.004966222, 'fake_loss': 0.004966222}\n",
      "{'k': -0.49756888, 'measure': 0.005706328455533366, 'real_loss': 0.0030127387, 'fake_loss': 0.0030127387}\n",
      "{'k': -0.4993046, 'measure': 0.005211697938095313, 'real_loss': 0.00553192, 'fake_loss': 0.00553192}\n",
      "{'k': -0.50110817, 'measure': 0.005410783201223239, 'real_loss': 0.0043129465, 'fake_loss': 0.0043129465}\n",
      "{'k': -0.50283253, 'measure': 0.005179450546042063, 'real_loss': 0.0017480656, 'fake_loss': 0.0017480656}\n",
      "{'k': -0.50447303, 'measure': 0.004924104881007224, 'real_loss': 0.0075029545, 'fake_loss': 0.0075029545}\n",
      "{'k': -0.5061626, 'measure': 0.005079964608710725, 'real_loss': 0.0041062394, 'fake_loss': 0.0041062394}\n",
      "{'k': -0.50784224, 'measure': 0.0050451697313692425, 'real_loss': 0.004274483, 'fake_loss': 0.004274483}\n",
      "{'k': -0.50953525, 'measure': 0.005079010571935214, 'real_loss': 0.0025084582, 'fake_loss': 0.0025084582}\n",
      "{'k': -0.51117903, 'measure': 0.004935003784310539, 'real_loss': 0.0026963972, 'fake_loss': 0.0026963972}\n",
      "{'k': -0.51284647, 'measure': 0.005006418336066417, 'real_loss': 0.0016429271, 'fake_loss': 0.0016429271}\n",
      "{'k': -0.5144317, 'measure': 0.0047582692278083415, 'real_loss': 0.0015771703, 'fake_loss': 0.0015771703}\n",
      "{'k': -0.5159876, 'measure': 0.004669932087650522, 'real_loss': 0.002040232, 'fake_loss': 0.002040232}\n",
      "{'k': -0.5176437, 'measure': 0.0049713063798844815, 'real_loss': 0.0040448075, 'fake_loss': 0.0040448075}\n",
      "{'k': -0.51919085, 'measure': 0.004641587518213783, 'real_loss': 0.0073659774, 'fake_loss': 0.0073659774}\n",
      "{'k': -0.5207409, 'measure': 0.004661208526580594, 'real_loss': 0.0019938077, 'fake_loss': 0.0019938077}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': -0.52230227, 'measure': 0.004687032556801569, 'real_loss': 0.001878124, 'fake_loss': 0.001878124}\n",
      "{'k': -0.5238055, 'measure': 0.004512460932775866, 'real_loss': 0.0040942356, 'fake_loss': 0.0040942356}\n",
      "{'k': -0.5252268, 'measure': 0.0042700398536981085, 'real_loss': 0.0034222677, 'fake_loss': 0.0034222677}\n",
      "{'k': -0.52672905, 'measure': 0.004511998969770502, 'real_loss': 0.0015298049, 'fake_loss': 0.0015298049}\n",
      "{'k': -0.5283249, 'measure': 0.004787489141745027, 'real_loss': 0.004154928, 'fake_loss': 0.004154928}\n",
      "{'k': -0.52981997, 'measure': 0.004491429425426759, 'real_loss': 0.0041177543, 'fake_loss': 0.0041177543}\n",
      "{'k': -0.5313023, 'measure': 0.004453169354062993, 'real_loss': 0.0068964465, 'fake_loss': 0.0068964465}\n",
      "{'k': -0.53282726, 'measure': 0.0045852587987319565, 'real_loss': 0.0039624916, 'fake_loss': 0.0039624916}\n",
      "{'k': -0.5343019, 'measure': 0.00442972721013939, 'real_loss': 0.003947408, 'fake_loss': 0.003947408}\n",
      "{'k': -0.53568995, 'measure': 0.0041701018090825525, 'real_loss': 0.0036921054, 'fake_loss': 0.0036921054}\n",
      "{'k': -0.5371848, 'measure': 0.0044844969590194525, 'real_loss': 0.0040550386, 'fake_loss': 0.0040550386}\n",
      "{'k': -0.5386322, 'measure': 0.0043483715347247195, 'real_loss': 0.0031906082, 'fake_loss': 0.0031906082}\n",
      "{'k': -0.5400561, 'measure': 0.004276573182432912, 'real_loss': 0.0024016942, 'fake_loss': 0.0024016942}\n",
      "{'k': -0.5414614, 'measure': 0.004219554132549092, 'real_loss': 0.0022930605, 'fake_loss': 0.0022930605}\n",
      "{'k': -0.5429456, 'measure': 0.004456025324470829, 'real_loss': 0.0016223872, 'fake_loss': 0.0016223872}\n",
      "{'k': -0.5443033, 'measure': 0.0040730860923067665, 'real_loss': 0.002857067, 'fake_loss': 0.002857067}\n",
      "{'k': -0.5456226, 'measure': 0.00396209563332377, 'real_loss': 0.0022292873, 'fake_loss': 0.0022292873}\n",
      "{'k': -0.5471146, 'measure': 0.004479449387930799, 'real_loss': 0.0022698292, 'fake_loss': 0.0022698292}\n",
      "{'k': -0.5485172, 'measure': 0.004211178340134211, 'real_loss': 0.00228828, 'fake_loss': 0.00228828}\n",
      "{'k': -0.54978174, 'measure': 0.0037970092560863124, 'real_loss': 0.0026779294, 'fake_loss': 0.0026779294}\n",
      "{'k': -0.55114573, 'measure': 0.004095899391453713, 'real_loss': 0.003877516, 'fake_loss': 0.003877516}\n",
      "{'k': -0.55261666, 'measure': 0.00441281330678612, 'real_loss': 0.0038690076, 'fake_loss': 0.0038690076}\n",
      "{'k': -0.5540086, 'measure': 0.004181657422624994, 'real_loss': 0.0018864663, 'fake_loss': 0.0018864663}\n",
      "{'k': -0.55537343, 'measure': 0.004097315809456632, 'real_loss': 0.0029299343, 'fake_loss': 0.0029299343}\n"
     ]
    }
   ],
   "source": [
    "# k의 갱신에 이용할 파라미터\n",
    "GAMMA = 0.5\n",
    "LR_K = 0.001\n",
    "\n",
    "# 반복 수. 100000～1000000 정도로 지정\n",
    "TOTAL_STEPS = 100000\n",
    "\n",
    "# 모델과 확인용 생성 이미지를 저장할 폴더\n",
    "MODEL_SAVE_DIR = 'began/models'\n",
    "IMG_SAVE_DIR = 'began/imgs'\n",
    "# 확인용으로 5x5 개의 이미지를 생성\n",
    "IMG_SAMPLE_SHAPE = (5, 5)\n",
    "N_IMG_SAMPLES = np.prod(IMG_SAMPLE_SHAPE)\n",
    "\n",
    "\n",
    "# 저장할 폴더가 없다면 생성\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(IMG_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 샘플이미지용 랜덤 시드\n",
    "sample_seeds = np.random.uniform(\n",
    "    -1, 1, (N_IMG_SAMPLES, z_size)\n",
    ")\n",
    "\n",
    "history = []\n",
    "logs = []\n",
    "\n",
    "for step, batch in enumerate(train_data_generator):\n",
    "    # 샘플 수가 BATCH_SIZE를 만족하지 않으면 스킵\n",
    "    # 전체 이미지의 개수가 BATCH_SIZE의 배수가 아닌 경우 발생\n",
    "    if len(batch) < BATCH_SIZE:\n",
    "        continue\n",
    "    \n",
    "    # 학습종료\n",
    "    if step > TOTAL_STEPS:\n",
    "        break\n",
    "\n",
    "    # 임의의 값 생성\n",
    "    z_g = np.random.uniform(\n",
    "        -1, 1, (BATCH_SIZE, z_size)\n",
    "    )\n",
    "    z_d = np.random.uniform(\n",
    "        -1, 1, (BATCH_SIZE, z_size)\n",
    "    )\n",
    "    \n",
    "    # 생성 이미지(구분자의 학습에 이용)\n",
    "    g_pred = generator.predict(z_d)\n",
    "    \n",
    "    # 생성자를 1스텝 학습시킨다\n",
    "    generator.train_on_batch(z_g, batch)\n",
    "    # 구분자를 1스텝 학습시킨다\n",
    "    _, real_loss, fake_loss = discriminator_trainer.train_on_batch(\n",
    "            [batch, g_pred],\n",
    "            [batch, g_pred]\n",
    "    )\n",
    "\n",
    "    # k 를 갱신\n",
    "    k_var += LR_K*(GAMMA*real_loss - fake_loss)\n",
    "    K.set_value(k, k_var)\n",
    "    \n",
    "\n",
    "    # g_measure 을 계산하기 위한 loss 저장\n",
    "    history.append({\n",
    "        'real_loss': real_loss,\n",
    "        'fake_loss': fake_loss\n",
    "    })\n",
    "\n",
    "    # 1000번에 1번씩 로그 표시\n",
    "    if step%1000 == 0:\n",
    "        # 과거 1000 번의 measure 의 평균\n",
    "        measurement = np.mean([\n",
    "            measure(\n",
    "                loss['real_loss'],\n",
    "                loss['fake_loss'],\n",
    "                GAMMA\n",
    "            )\n",
    "            for loss in history[-1000:]\n",
    "        ])\n",
    "        \n",
    "        logs.append({\n",
    "            'k': K.get_value(k),\n",
    "            'measure': measurement,\n",
    "            'real_loss': real_loss,\n",
    "            'fake_loss': fake_loss\n",
    "        })\n",
    "        print(logs[-1])\n",
    "\n",
    "        # 이미지 저장  \n",
    "        img_path = '{}/generated_{}.png'.format(\n",
    "            IMG_SAVE_DIR,\n",
    "            step\n",
    "        )\n",
    "        save_imgs(\n",
    "            img_path,\n",
    "            generator.predict(sample_seeds),\n",
    "            rows=IMG_SAMPLE_SHAPE[0],\n",
    "            cols=IMG_SAMPLE_SHAPE[1]\n",
    "        )\n",
    "        # 최신 모델 저장\n",
    "        generator.save('{}/generator_{}.hd5'.format(MODEL_SAVE_DIR, step))\n",
    "        discriminator.save('{}/discriminator_{}.hd5'.format(MODEL_SAVE_DIR, step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "BEGAN.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
