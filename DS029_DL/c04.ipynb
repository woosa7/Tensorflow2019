{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제4장 신경망과 케라스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 예제 코드4.1:데이터 불러오기 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (60000, 28, 28)\n",
      "x_test.shape: (10000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 임포트한 데이터의 형태 확인\n",
    "print('x_train.shape:', x_train.shape)\n",
    "print('x_test.shape:', x_test.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 예제 코드4.3:임포트한 데이터의 스케일 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_train = x_train/255.\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 예제 코드4.4:임포트한 데이터(클래스 레이블)를 네트워크에 맞게 변형 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 예제 코드4.5:모델 구축 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(units=64, input_shape=(784,), activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 예제 코드4.8:Adam을 이용한 모델의 MNIST 데이터 학습 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.3249 - acc: 0.9078 - val_loss: 0.1813 - val_acc: 0.9505\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.1587 - acc: 0.9544 - val_loss: 0.1353 - val_acc: 0.9621\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.1157 - acc: 0.9671 - val_loss: 0.1185 - val_acc: 0.9662\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0903 - acc: 0.9741 - val_loss: 0.1136 - val_acc: 0.9670\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 4s 73us/sample - loss: 0.0754 - acc: 0.9779 - val_loss: 0.0976 - val_acc: 0.9720\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.0618 - acc: 0.9812 - val_loss: 0.0984 - val_acc: 0.9715\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0521 - acc: 0.9841 - val_loss: 0.1004 - val_acc: 0.9709\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.0444 - acc: 0.9868 - val_loss: 0.0975 - val_acc: 0.9719\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0373 - acc: 0.9885 - val_loss: 0.1072 - val_acc: 0.9694\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.0329 - acc: 0.9897 - val_loss: 0.0971 - val_acc: 0.9727\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.0275 - acc: 0.9919 - val_loss: 0.1083 - val_acc: 0.9705\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.0239 - acc: 0.9926 - val_loss: 0.1088 - val_acc: 0.9722\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0209 - acc: 0.9941 - val_loss: 0.1061 - val_acc: 0.9724\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0185 - acc: 0.9945 - val_loss: 0.1056 - val_acc: 0.9727\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0144 - acc: 0.9965 - val_loss: 0.1078 - val_acc: 0.9736\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.0139 - acc: 0.9959 - val_loss: 0.1227 - val_acc: 0.9693\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.0138 - acc: 0.9960 - val_loss: 0.1179 - val_acc: 0.9719\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 4s 73us/sample - loss: 0.0111 - acc: 0.9967 - val_loss: 0.1238 - val_acc: 0.9722\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0093 - acc: 0.9975 - val_loss: 0.1257 - val_acc: 0.9725\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0094 - acc: 0.9976 - val_loss: 0.1326 - val_acc: 0.9719\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "tsb = TensorBoard(log_dir='./logs')\n",
    "\n",
    "history_adam = model.fit(x_train, y_train,\n",
    "                         batch_size=32,\n",
    "                         epochs=20,\n",
    "                         validation_split=0.2,\n",
    "                         callbacks=[tsb]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 예제 코드4.9:Functional API를 이용한 모델 구축 준비**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_train = x_train/255.\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test/255.\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "tsb = TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 예제 코드4.10:Functional API로 모델 구축 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(784, ))\n",
    "middle = Dense(units=64, activation='relu')(input)\n",
    "output = Dense(units=10, activation='softmax')(middle)\n",
    "\n",
    "model = Model(inputs=[input], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 예제 코드4.11:구축한 모델의 컴파일 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 예제 코드4.12:MNIST 데이터 세트를 학습 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s 73us/sample - loss: 0.3402 - acc: 0.9049 - val_loss: 0.1907 - val_acc: 0.9464\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.1638 - acc: 0.9532 - val_loss: 0.1438 - val_acc: 0.9598\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1196 - acc: 0.9658 - val_loss: 0.1286 - val_acc: 0.9624\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0946 - acc: 0.9719 - val_loss: 0.1163 - val_acc: 0.9665\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0771 - acc: 0.9768 - val_loss: 0.1024 - val_acc: 0.9691\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.0643 - acc: 0.9809 - val_loss: 0.0998 - val_acc: 0.9699\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0532 - acc: 0.9840 - val_loss: 0.0978 - val_acc: 0.9708\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.0464 - acc: 0.9863 - val_loss: 0.0992 - val_acc: 0.9703\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0378 - acc: 0.9888 - val_loss: 0.1039 - val_acc: 0.9702\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0336 - acc: 0.9902 - val_loss: 0.1005 - val_acc: 0.9733\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 4s 73us/sample - loss: 0.0303 - acc: 0.9909 - val_loss: 0.1135 - val_acc: 0.9691\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.0251 - acc: 0.9927 - val_loss: 0.1101 - val_acc: 0.9702\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.0217 - acc: 0.9939 - val_loss: 0.1101 - val_acc: 0.9709\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.0194 - acc: 0.9942 - val_loss: 0.1101 - val_acc: 0.9705\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0174 - acc: 0.9949 - val_loss: 0.1148 - val_acc: 0.9735\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s 73us/sample - loss: 0.0162 - acc: 0.9951 - val_loss: 0.1091 - val_acc: 0.9721\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s 68us/sample - loss: 0.0120 - acc: 0.9969 - val_loss: 0.1202 - val_acc: 0.9718\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.0131 - acc: 0.9963 - val_loss: 0.1187 - val_acc: 0.9721\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.0105 - acc: 0.9970 - val_loss: 0.1182 - val_acc: 0.9722\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.0097 - acc: 0.9974 - val_loss: 0.1197 - val_acc: 0.9722\n"
     ]
    }
   ],
   "source": [
    "history_adam = model.fit(x_train, y_train,\n",
    "                         batch_size=32,\n",
    "                         epochs=20,\n",
    "                         validation_split=0.2,\n",
    "                         callbacks=[tsb]\n",
    "                        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
